{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GroundTruthBounding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMMPLTHo4Xab8yPDTvPZ68f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZnattapolZ/Enhancing-The-Visualization-of-Latent-Fingerprint/blob/main/%5BData%20Preparation%5D%20-%20Groundtruth%20Bounding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp4jiEoWUSKu"
      },
      "source": [
        "#**Bounding The Ground truth from impression**\n",
        "(the impression and ground truth comes from Anguli mentioned in this repo: https://github.com/JanSvob/fingerprint_gae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxLOytsFK-H5"
      },
      "source": [
        "## **Connect to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4XeJofxK7kR",
        "outputId": "d950b986-7251-4305-a4a6-b15e4e92df6c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj5v6ebpVnLE"
      },
      "source": [
        "## **PATH and Library Import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e3ijru3VFJc"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import glob\n",
        "import datetime\n",
        "import os\n",
        "import random\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MFNHu8kUI-d"
      },
      "source": [
        "TRAIN_NO_NOISE_PATH = '/content/drive/MyDrive/data_samples/synth_data/train_no_noise/'\n",
        "TRAIN_NOISE_PATH = '/content/drive/MyDrive/data_samples/synth_data/train_noise/'\n",
        "TRAIN_GT_PATH = '/content/drive/MyDrive/data_samples/synth_data/train_ground/'\n",
        "\n",
        "TEST_NO_NOISE_PATH = '/content/drive/MyDrive/data_samples/synth_data/test_no_noise/'\n",
        "TEST_NOISE_PATH = '/content/drive/MyDrive/data_samples/synth_data/test_noise/'\n",
        "TEST_GT_PATH = '/content/drive/MyDrive/data_samples/synth_data/test_ground/'\n",
        "\n",
        "ORIGINAL_FOLDER = 'original/'\n",
        "PREPROCESSED_FOLDER = 'preprocessed/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt_rwaA4rzSO"
      },
      "source": [
        "## **Get train set paths**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfUY-fHzzu02"
      },
      "source": [
        "# Get train set paths\n",
        "def make_path_list(parent_path):\n",
        "  path_list = []\n",
        "  for i in range(1, 11):\n",
        "    temp_list = [f for f in glob.glob(parent_path + 'fp_' + str(i) + '/*.png')]\n",
        "    path_list.append(temp_list)\n",
        "  flat_list = [item for sublist in path_list for item in sublist]\n",
        "  return flat_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-HVVbQG0xp4"
      },
      "source": [
        "train_no_noise_paths = make_path_list(TRAIN_NO_NOISE_PATH)\n",
        "train_noise_paths = make_path_list(TRAIN_NOISE_PATH)\n",
        "train_gt_paths = make_path_list(TRAIN_GT_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0qwmJsu1px1",
        "outputId": "3d4f7ff7-2b45-45fb-a7ef-d3bc4eaafd9c"
      },
      "source": [
        "print('train_no_noise length:', len(train_no_noise_paths))\n",
        "print('train_noise length:', len(train_noise_paths))\n",
        "print('train_gt length:', len(train_gt_paths))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_no_noise length: 10000\n",
            "train_noise length: 10000\n",
            "train_gt length: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3H6SM2fV3u5"
      },
      "source": [
        "# **Get Train Image Path and Create DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0Q6njlAWBHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "160bb77a-569b-41c5-e7a8-daa00b9223f9"
      },
      "source": [
        "train_no_noise_paths.sort()\n",
        "train_noise_paths.sort()\n",
        "train_gt_paths.sort()\n",
        "\n",
        "print('train_no_noise number:', len(train_no_noise_paths))\n",
        "print('train_noise number:', len(train_noise_paths))\n",
        "print('train_gt number:', len(train_gt_paths))\n",
        "\n",
        "train_data_paths = {\n",
        "  'noise': train_noise_paths,\n",
        "  'no_noise': train_no_noise_paths,\n",
        "  'ground_truth': train_gt_paths\n",
        "}\n",
        "\n",
        "train_path_df = pd.DataFrame(data = train_data_paths)\n",
        "print(train_path_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_no_noise number: 10000\n",
            "train_noise number: 10000\n",
            "train_gt number: 10000\n",
            "                                               noise  ...                                       ground_truth\n",
            "0  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "1  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "2  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "3  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "4  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_hVjGzklOoc",
        "outputId": "d1ffa2a0-d016-41c6-ee43-7d48c5ab9118"
      },
      "source": [
        "# train_no_noise_path = [f for f in glob.glob(TRAIN_NO_NOISE_PATH + ORIGINAL_FOLDER + '*.png')]\n",
        "# train_no_noise_path.sort()\n",
        "\n",
        "train_noise_path = [f for f in glob.glob(TRAIN_NOISE_PATH + PREPROCESSED_FOLDER + '*.png')]\n",
        "train_noise_path.sort()\n",
        "\n",
        "# train_gt_path = [f for f in glob.glob(TRAIN_GT_PATH + ORIGINAL_FOLDER + '*.png')]\n",
        "# train_gt_path.sort()\n",
        "\n",
        "# print('train_no_noise number:', len(train_no_noise_path))\n",
        "print('train_noise number:', len(train_noise_path))\n",
        "# print('train_gt number:', len(train_gt_path))\n",
        "\n",
        "train_data_paths = {\n",
        "  'noise': train_noise_path,\n",
        "  # 'no_noise': train_no_noise_path,\n",
        "  # 'ground_truth': train_gt_path\n",
        "}\n",
        "\n",
        "train_path_df = pd.DataFrame(data = train_data_paths)\n",
        "print(train_path_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_noise number: 10000\n",
            "                                               noise\n",
            "0  /content/drive/MyDrive/data_samples/synth_data...\n",
            "1  /content/drive/MyDrive/data_samples/synth_data...\n",
            "2  /content/drive/MyDrive/data_samples/synth_data...\n",
            "3  /content/drive/MyDrive/data_samples/synth_data...\n",
            "4  /content/drive/MyDrive/data_samples/synth_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Voi31jt-wvlS",
        "outputId": "37e13137-d54c-479f-99a5-cf01e875c635"
      },
      "source": [
        "train_path_df.noise[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/data_samples/synth_data/train_noise/preprocessed/1.png'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXoi-4UndxRF"
      },
      "source": [
        "# **Get Test Image Path and Create DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5A70bh7dXla",
        "outputId": "8f26d015-61ee-4425-9733-c5b7ebb0220d"
      },
      "source": [
        "test_no_noise_path = [f for f in glob.glob(TEST_NO_NOISE_PATH + ORIGINAL_FOLDER + '*.png')]\n",
        "test_no_noise_path.sort()\n",
        "\n",
        "test_noise_path = [f for f in glob.glob(TEST_NOISE_PATH + ORIGINAL_FOLDER + '*.png')]\n",
        "test_noise_path.sort()\n",
        "\n",
        "test_gt_path = [f for f in glob.glob(TEST_GT_PATH + ORIGINAL_FOLDER + '*.png')]\n",
        "test_gt_path.sort()\n",
        "\n",
        "print('test_no_noise number:', len(test_no_noise_path))\n",
        "print('test_noise number:', len(test_noise_path))\n",
        "print('test_gt number:', len(test_gt_path))\n",
        "\n",
        "test_data_paths = {\n",
        "  'noise': test_noise_path,\n",
        "  'no_noise': test_no_noise_path,\n",
        "  'ground_truth': test_gt_path\n",
        "}\n",
        "\n",
        "test_path_df = pd.DataFrame(data = test_data_paths)\n",
        "print(test_path_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_no_noise number: 500\n",
            "test_noise number: 500\n",
            "test_gt number: 500\n",
            "                                                 noise  ...                                       ground_truth\n",
            "0    /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "1    /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "2    /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "3    /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "4    /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "..                                                 ...  ...                                                ...\n",
            "495  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "496  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "497  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "498  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "499  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "\n",
            "[500 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsLB6igqXED5"
      },
      "source": [
        "def get_image_batch(paths, resize=True, resize_dim=(275, 400)):\n",
        "  image_list = []\n",
        "  for path in paths:\n",
        "    img = cv2.imread(path, 0)\n",
        "    if (resize):\n",
        "      img = cv2.resize(img, resize_dim, interpolation = cv2.INTER_NEAREST)\n",
        "      _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    image_list.append(img / 255)\n",
        "\n",
        "  return image_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJywq5TCcRjA"
      },
      "source": [
        "## Bounding the Ground Truth\n",
        "(run kernel in imprint image and check wheather it's have latent or not)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp_1xp3xcQE0"
      },
      "source": [
        "KERNEL_SIZE = (3,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-n4-AkTX0Ii"
      },
      "source": [
        "def pad_image(img, pad_t, pad_b, pad_l, pad_r):\n",
        "  padded_img = cv2.copyMakeBorder(img, pad_t, pad_b, pad_l, pad_r, cv2.BORDER_REFLECT)\n",
        "  return padded_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuIcu-5VdYPa"
      },
      "source": [
        "# note the images dim have to be exact the same\n",
        "def bound_ground_truth_image(imprint_imgs, \n",
        "                             ground_imgs, \n",
        "                             image_index,\n",
        "                             saving_path,\n",
        "                             kernel_size = (10,10), \n",
        "                             dilation_kernel_size = (15,15), \n",
        "                             accepted_ratio = 0):\n",
        "  padding = False\n",
        "  half_kernel = math.ceil(kernel_size[0]/2)\n",
        "\n",
        "  img_width = imprint_imgs[0].shape[0]\n",
        "  img_height = imprint_imgs[0].shape[1]\n",
        "\n",
        "  accepted_black_dot_count = math.ceil((kernel_size[0] * kernel_size[1]) * accepted_ratio)\n",
        "  # print(accepted_black_dot_count)\n",
        "\n",
        "  if (img_width % kernel_size[1] != 0 or img_height % kernel_size[0] != 0):\n",
        "    padding = True\n",
        "    pad_l = math.floor(kernel_size[0]/2)\n",
        "    pad_r = math.ceil(kernel_size[0]/2)\n",
        "    pad_t = math.floor(kernel_size[1]/2)\n",
        "    pad_b = math.ceil(kernel_size[1]/2)\n",
        "    img_width = img_width + pad_l + pad_r\n",
        "    img_height = img_height + pad_t + pad_b\n",
        "    \n",
        "  dilation_filter = np.ones(dilation_kernel_size)\n",
        "  white_filter = np.ones(kernel_size)\n",
        "  black_filter = np.zeros(kernel_size)\n",
        "  row_iteration = math.floor(img_width / kernel_size[0])\n",
        "  col_iteration = math.floor(img_height / kernel_size[1])\n",
        "\n",
        "  start_time = datetime.datetime.now()\n",
        "  print('Bounding Progression |', end = '')\n",
        "  \n",
        "  for n, img in enumerate(imprint_imgs):\n",
        "    # plt.imshow(img, 'gray'), plt.show()\n",
        "\n",
        "    # img = cv2.erode(img, dilation_filter, 1)\n",
        "    for i in range(1):\n",
        "      img = cv2.erode(img, dilation_filter, 1)\n",
        "    for i in range(1):\n",
        "      img = cv2.dilate(img, dilation_filter, 1)\n",
        "  \n",
        "    # plt.imshow(img, 'gray'), plt.show()\n",
        "  \n",
        "    if (padding):\n",
        "      img = pad_image(img, pad_t, pad_b, pad_l, pad_r)\n",
        "      ground_imgs[n] = pad_image(ground_imgs[n], pad_t, pad_b, pad_l, pad_r)\n",
        "    \n",
        "    if (n % 10 == 0):\n",
        "      print('*', end = '')\n",
        "\n",
        "    for i in range(row_iteration):\n",
        "      for j in range(col_iteration):\n",
        "        has_no_info = np.logical_and(img[i * kernel_size[0] : (i + 1) * kernel_size[0], j * kernel_size[1] : (j + 1) * kernel_size[1]], white_filter)\n",
        "        false_count = sum([list(f).count(False) for f in has_no_info])\n",
        "        if (false_count <= accepted_black_dot_count):\n",
        "          ground_imgs[n][i * kernel_size[0] : (i + 1) * kernel_size[0], j * kernel_size[1] : (j + 1) * kernel_size[1]] = black_filter\n",
        "    \n",
        "    if (padding):\n",
        "      img = img[pad_l:(img_width - pad_r), pad_t: (img_height - pad_b)]\n",
        "      ground_imgs[n] = ground_imgs[n][pad_l:(img_width - pad_r), pad_t: (img_height - pad_b)]\n",
        "    \n",
        "    # Saving bounded ground truth\n",
        "    # plt.imshow(ground_imgs[n], 'gray'), plt.show()\n",
        "    cv2.imwrite(saving_path + image_index[n], ground_imgs[n] * 255)\n",
        "\n",
        "  print('|', end = '\\n')\n",
        "  print('Time used : ', start_time - datetime.datetime.now())\n",
        "  return \n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43ZLHCS4dUER"
      },
      "source": [
        "def migrate_data(source_paths_list, des_path):\n",
        "  for i, path in enumerate(source_paths_list):\n",
        "    img = Image.open(path)\n",
        "    file_name = os.path.basename(path)\n",
        "    img.save(des_path + file_name)\n",
        "    progression_percent = ((i - 1) / len(source_paths_list)) * 100\n",
        "    if progression_percent % 10 == 0:\n",
        "      print('Progression percent:', str(progression_percent))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzY9Bal_eYmU",
        "outputId": "bc3054c0-979a-4599-e623-e545d44829a8"
      },
      "source": [
        "migrate_data(train_path_df.noise, TRAIN_NOISE_PATH + PREPROCESSED_FOLDER)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progression percent: 0.0\n",
            "Progression percent: 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVxEpwS-sTZB"
      },
      "source": [
        "def extract_image_name(path_list):\n",
        "  extracted_list = []\n",
        "  for path in path_list:\n",
        "    file_name = os.path.basename(path)\n",
        "    extracted_list.append(file_name)\n",
        "  return extracted_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuNmTipukm26"
      },
      "source": [
        "def perform_bounding(path_df, batch, bounded_saving_path):\n",
        "  path_length = len(path_df.no_noise)\n",
        "  batch_size = math.ceil(path_length / batch)\n",
        "\n",
        "  for round in range(batch):\n",
        "    start_of_batch = round * batch_size\n",
        "    end_of_batch = (start_of_batch + batch_size)\n",
        "\n",
        "    print('batch:', str(round), '=> ' + str(start_of_batch) + ' - ' + str(end_of_batch - 1))\n",
        "\n",
        "    no_noise_img = get_image_batch(path_df.no_noise[start_of_batch:end_of_batch])\n",
        "    gt_img = get_image_batch(path_df.ground_truth[start_of_batch:end_of_batch])\n",
        "\n",
        "    print('total image:', len(no_noise_img))    \n",
        "    index_list = extract_image_name(path_df.no_noise[start_of_batch:end_of_batch])\n",
        "    bound_ground_truth_image(no_noise_img, gt_img, index_list, bounded_saving_path, KERNEL_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yeumOzm3jI3",
        "outputId": "f73e61f9-8ec8-483d-ed96-e1c7e68c71fe"
      },
      "source": [
        "# Perform bounding on ground truth images of train set\n",
        "perform_bounding(train_path_df, 100, TRAIN_GT_PATH + PREPROCESSED_FOLDER)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch: 0 => 0 - 99\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.517219\n",
            "batch: 1 => 100 - 199\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.000461\n",
            "batch: 2 => 200 - 299\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.138750\n",
            "batch: 3 => 300 - 399\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.014591\n",
            "batch: 4 => 400 - 499\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.132197\n",
            "batch: 5 => 500 - 599\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.812569\n",
            "batch: 6 => 600 - 699\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.982399\n",
            "batch: 7 => 700 - 799\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.083012\n",
            "batch: 8 => 800 - 899\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.819210\n",
            "batch: 9 => 900 - 999\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.939971\n",
            "batch: 10 => 1000 - 1099\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.074033\n",
            "batch: 11 => 1100 - 1199\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.908309\n",
            "batch: 12 => 1200 - 1299\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.199907\n",
            "batch: 13 => 1300 - 1399\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.034619\n",
            "batch: 14 => 1400 - 1499\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.995738\n",
            "batch: 15 => 1500 - 1599\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.186954\n",
            "batch: 16 => 1600 - 1699\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.063547\n",
            "batch: 17 => 1700 - 1799\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.020658\n",
            "batch: 18 => 1800 - 1899\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.979733\n",
            "batch: 19 => 1900 - 1999\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.839011\n",
            "batch: 20 => 2000 - 2099\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.155505\n",
            "batch: 21 => 2100 - 2199\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.911856\n",
            "batch: 22 => 2200 - 2299\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.260895\n",
            "batch: 23 => 2300 - 2399\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.041608\n",
            "batch: 24 => 2400 - 2499\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.018769\n",
            "batch: 25 => 2500 - 2599\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.871350\n",
            "batch: 26 => 2600 - 2699\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.211848\n",
            "batch: 27 => 2700 - 2799\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.850592\n",
            "batch: 28 => 2800 - 2899\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.022672\n",
            "batch: 29 => 2900 - 2999\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.046194\n",
            "batch: 30 => 3000 - 3099\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.920822\n",
            "batch: 31 => 3100 - 3199\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.238284\n",
            "batch: 32 => 3200 - 3299\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.919145\n",
            "batch: 33 => 3300 - 3399\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.191325\n",
            "batch: 34 => 3400 - 3499\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.332367\n",
            "batch: 35 => 3500 - 3599\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.026587\n",
            "batch: 36 => 3600 - 3699\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.264788\n",
            "batch: 37 => 3700 - 3799\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.214201\n",
            "batch: 38 => 3800 - 3899\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.038899\n",
            "batch: 39 => 3900 - 3999\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.142256\n",
            "batch: 40 => 4000 - 4099\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.075751\n",
            "batch: 41 => 4100 - 4199\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.985168\n",
            "batch: 42 => 4200 - 4299\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.186073\n",
            "batch: 43 => 4300 - 4399\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.155188\n",
            "batch: 44 => 4400 - 4499\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.348833\n",
            "batch: 45 => 4500 - 4599\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.069422\n",
            "batch: 46 => 4600 - 4699\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.140145\n",
            "batch: 47 => 4700 - 4799\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.076476\n",
            "batch: 48 => 4800 - 4899\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.291233\n",
            "batch: 49 => 4900 - 4999\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.349613\n",
            "batch: 50 => 5000 - 5099\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.058296\n",
            "batch: 51 => 5100 - 5199\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.183154\n",
            "batch: 52 => 5200 - 5299\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.233381\n",
            "batch: 53 => 5300 - 5399\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.229177\n",
            "batch: 54 => 5400 - 5499\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.033234\n",
            "batch: 55 => 5500 - 5599\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.022692\n",
            "batch: 56 => 5600 - 5699\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.126049\n",
            "batch: 57 => 5700 - 5799\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.890781\n",
            "batch: 58 => 5800 - 5899\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.236149\n",
            "batch: 59 => 5900 - 5999\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.261348\n",
            "batch: 60 => 6000 - 6099\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.114901\n",
            "batch: 61 => 6100 - 6199\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.065704\n",
            "batch: 62 => 6200 - 6299\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.110550\n",
            "batch: 63 => 6300 - 6399\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.937125\n",
            "batch: 64 => 6400 - 6499\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.313244\n",
            "batch: 65 => 6500 - 6599\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.971000\n",
            "batch: 66 => 6600 - 6699\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.161314\n",
            "batch: 67 => 6700 - 6799\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.388718\n",
            "batch: 68 => 6800 - 6899\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.984216\n",
            "batch: 69 => 6900 - 6999\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.173141\n",
            "batch: 70 => 7000 - 7099\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.140412\n",
            "batch: 71 => 7100 - 7199\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.231702\n",
            "batch: 72 => 7200 - 7299\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.192241\n",
            "batch: 73 => 7300 - 7399\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.093848\n",
            "batch: 74 => 7400 - 7499\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.997823\n",
            "batch: 75 => 7500 - 7599\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.238154\n",
            "batch: 76 => 7600 - 7699\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:37.992872\n",
            "batch: 77 => 7700 - 7799\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.223223\n",
            "batch: 78 => 7800 - 7899\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.169888\n",
            "batch: 79 => 7900 - 7999\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.266071\n",
            "batch: 80 => 8000 - 8099\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.198895\n",
            "batch: 81 => 8100 - 8199\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.048717\n",
            "batch: 82 => 8200 - 8299\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.021002\n",
            "batch: 83 => 8300 - 8399\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.235260\n",
            "batch: 84 => 8400 - 8499\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.001636\n",
            "batch: 85 => 8500 - 8599\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.290773\n",
            "batch: 86 => 8600 - 8699\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.077698\n",
            "batch: 87 => 8700 - 8799\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.017063\n",
            "batch: 88 => 8800 - 8899\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.150974\n",
            "batch: 89 => 8900 - 8999\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.246865\n",
            "batch: 90 => 9000 - 9099\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.199670\n",
            "batch: 91 => 9100 - 9199\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.071789\n",
            "batch: 92 => 9200 - 9299\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.052568\n",
            "batch: 93 => 9300 - 9399\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.045795\n",
            "batch: 94 => 9400 - 9499\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.097690\n",
            "batch: 95 => 9500 - 9599\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.193497\n",
            "batch: 96 => 9600 - 9699\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.021072\n",
            "batch: 97 => 9700 - 9799\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.208797\n",
            "batch: 98 => 9800 - 9899\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.046191\n",
            "batch: 99 => 9900 - 9999\n",
            "total image: 100\n",
            "Bounding Progression |*|\n",
            "Time used :  -1 day, 23:59:38.099671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf5r0Qu7lWuJ",
        "outputId": "2f7633b7-ecf0-4a31-a49e-7428d9694316"
      },
      "source": [
        "# Perform bounding on ground truth images of test set\n",
        "perform_bounding(test_path_df, 5, TEST_GT_PATH + PREPROCESSED_FOLDER)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch: 0 => 0 - 100\n",
            "100\n",
            "0\n",
            "Bounding Progression |****************************************************************************************************|\n",
            "Time used :  -1 day, 23:59:34.674504\n",
            "batch: 1 => 100 - 200\n",
            "100\n",
            "0\n",
            "Bounding Progression |****************************************************************************************************|\n",
            "Time used :  -1 day, 23:59:34.414459\n",
            "batch: 2 => 200 - 300\n",
            "100\n",
            "0\n",
            "Bounding Progression |****************************************************************************************************|\n",
            "Time used :  -1 day, 23:59:33.893720\n",
            "batch: 3 => 300 - 400\n",
            "100\n",
            "0\n",
            "Bounding Progression |****************************************************************************************************|\n",
            "Time used :  -1 day, 23:59:34.461921\n",
            "batch: 4 => 400 - 500\n",
            "100\n",
            "0\n",
            "Bounding Progression |****************************************************************************************************|\n",
            "Time used :  -1 day, 23:59:34.801739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfcmIrWM54ii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e2746ac-8130-4998-a3d8-35b2fcf4bc5e"
      },
      "source": [
        "# Add preprocessed paths of train set\n",
        "train_gt_preprocessed_path = [f for f in glob.glob(TRAIN_GT_PATH + PREPROCESSED_FOLDER + '*.png')]\n",
        "train_gt_preprocessed_path.sort()\n",
        "\n",
        "train_path_df['pre_processed'] = train_gt_preprocessed_path\n",
        "print(train_path_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               noise                                      pre_processed\n",
            "0  /content/drive/MyDrive/data_samples/synth_data...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "1  /content/drive/MyDrive/data_samples/synth_data...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "2  /content/drive/MyDrive/data_samples/synth_data...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "3  /content/drive/MyDrive/data_samples/synth_data...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "4  /content/drive/MyDrive/data_samples/synth_data...  /content/drive/MyDrive/data_samples/synth_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQfY_aAut6-k",
        "outputId": "f6cac993-8ede-4338-cc77-93d596ba70ca"
      },
      "source": [
        "# Add preprocessed paths of test set\n",
        "test_gt_preprocessed_path = [f for f in glob.glob(TEST_GT_PATH + PREPROCESSED_FOLDER + '*.png')]\n",
        "test_gt_preprocessed_path.sort()\n",
        "\n",
        "test_path_df['pre_processed'] = test_gt_preprocessed_path\n",
        "print(test_path_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               noise  ...                                      pre_processed\n",
            "0  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "1  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "2  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "3  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "4  /content/drive/MyDrive/data_samples/synth_data...  ...  /content/drive/MyDrive/data_samples/synth_data...\n",
            "\n",
            "[5 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z178wP3yt3Ke"
      },
      "source": [
        "# Rotate image\n",
        "def perform_rotate(path_df, \n",
        "                   minimum_degree, \n",
        "                   maximum_degree, \n",
        "                   noise_saving_path, \n",
        "                   gt_saving_path,\n",
        "                   show_output_image=False):\n",
        "  num_of_img = len(path_df.noise)\n",
        "  noise_file_name = extract_image_name(path_df.noise)\n",
        "  gt_file_name = extract_image_name(path_df.pre_processed)\n",
        "\n",
        "  if noise_file_name == gt_file_name:\n",
        "    print('filename are match.')\n",
        "\n",
        "    for i in range(num_of_img):\n",
        "      progression_percent = ((i + 1) / num_of_img) * 100\n",
        "      if progression_percent % 10 == 0:\n",
        "        print('Progression:', str(int(progression_percent)) + '%')\n",
        "\n",
        "      random_degree = random.randint(minimum_degree, maximum_degree)\n",
        "\n",
        "      noise_img = Image.open(path_df.noise[i])\n",
        "      gt_img = Image.open(path_df.pre_processed[i])\n",
        "\n",
        "      rotated_noise_img = noise_img.rotate(random_degree, fillcolor = 'white')\n",
        "      rotated_gt_img = gt_img.rotate(random_degree)\n",
        "\n",
        "      if show_output_image:\n",
        "        plt.imshow(rotated_noise_img, 'gray'), plt.show()\n",
        "        plt.imshow(rotated_gt_img, 'gray'), plt.show()\n",
        "\n",
        "      rotated_noise_img.save(noise_saving_path + noise_file_name[i])\n",
        "      rotated_gt_img.save(gt_saving_path + gt_file_name[i])\n",
        "  else:\n",
        "    print('filename not match.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs5DGSHzbTVX",
        "outputId": "afc93fd1-339d-4c96-b6a0-3de6bcd7093e"
      },
      "source": [
        "# Perform rotation on training set\n",
        "perform_rotate(train_path_df,\n",
        "               -8,\n",
        "               8,\n",
        "               noise_saving_path=TRAIN_NOISE_PATH + PREPROCESSED_FOLDER,\n",
        "               gt_saving_path=TRAIN_GT_PATH + PREPROCESSED_FOLDER)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "filename are match.\n",
            "Progression: 10%\n",
            "Progression: 20%\n",
            "Progression: 30%\n",
            "Progression: 40%\n",
            "Progression: 50%\n",
            "Progression: 60%\n",
            "Progression: 70%\n",
            "Progression: 80%\n",
            "Progression: 90%\n",
            "Progression: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFKap85a_YRB",
        "outputId": "606f2ee5-aa89-494f-d68a-9cd76bff1098"
      },
      "source": [
        "# Perform rotation on test set\n",
        "perform_rotate(test_path_df, \n",
        "               -8,\n",
        "               8,\n",
        "               noise_saving_path=TEST_NOISE_PATH + PREPROCESSED_FOLDER, \n",
        "               gt_saving_path=TEST_GT_PATH + PREPROCESSED_FOLDER)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "filename are match.\n",
            "Progression: 10%\n",
            "Progression: 20%\n",
            "Progression: 30%\n",
            "Progression: 40%\n",
            "Progression: 50%\n",
            "Progression: 60%\n",
            "Progression: 70%\n",
            "Progression: 80%\n",
            "Progression: 90%\n",
            "Progression: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCu7aDTq_oAA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}